#!/usr/bin/env python
# coding: utf-8

import streamlit as st
import time
import plotly.express as px
import pandas as pd
from .model_utils import load_summarization_models

def render_summarization_tab():
    st.header("๐ Arabic Text Summarization")
    st.markdown("**Compare Seq2Seq LSTM vs AraBART** for Arabic text summarization")
    
    # Load summarization models
    with st.spinner("Loading summarization models..."):
        seq2seq, arabart = load_summarization_models()
    
    # Check model availability
    seq2seq_available = seq2seq is not None and seq2seq.is_available()
    arabart_available = arabart is not None and arabart.is_available()
    
    if not seq2seq_available and not arabart_available:
        st.error("No summarization models available. Please ensure model files are present.")
        return
    
    # Model selection
    available_models = []
    if seq2seq_available:
        available_models.append("Seq2Seq LSTM")
    if arabart_available:
        available_models.append("AraBART")
    
    selected_models = st.multiselect(
        "Select Summarization Models:",
        available_models,
        default=available_models
    )
    
    if not selected_models:
        st.warning("Please select at least one model.")
        return
    
    # Input methods
    input_method = st.radio(
        "Input Method:",
        ["Type Text", "Upload File", "Sample Texts"]
    )
    
    input_text = ""
    
    if input_method == "Type Text":
        input_text = st.text_area(
            "Enter Arabic text to summarize:",
            height=200,
            placeholder="ุงูุชุจ ุงููุต ุงูุนุฑุจู ููุง ููุญุตูู ุนูู ููุฎุต..."
        )
    
    elif input_method == "Upload File":
        uploaded_file = st.file_uploader(
            "Upload text file (.txt)",
            type=['txt']
        )
        
        if uploaded_file is not None:
            try:
                input_text = str(uploaded_file.read(), "utf-8")
                st.success(f"File uploaded successfully! ({len(input_text)} characters)")
            except Exception as e:
                st.error(f"Error reading file: {str(e)}")
    
    elif input_method == "Sample Texts":
        sample_texts = {
            "Technology News": """
ุชุดูุฏ ุงูุชูููููุฌูุง ูู ุงูุนุงูู ุงูุนุฑุจู ุชุทูุฑุง ุณุฑูุนุง ูููุญูุธุง ูู ุงูุณููุงุช ุงูุฃุฎูุฑุฉุ ุญูุซ ุชุฒุงูุฏ ุงูุงุณุชุซูุงุฑ ูู ูุฌุงู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุงูุชุนูู ุงูุขูู. 
ููุฏ ุฃุทููุช ุงูุนุฏูุฏ ูู ุงูุฏูู ุงูุนุฑุจูุฉ ูุจุงุฏุฑุงุช ุทููุญุฉ ูุชุทููุฑ ุงููุทุงุน ุงูุชูููุ ุจูุง ูู ุฐูู ุฅูุดุงุก ูุฏู ุชูููุฉ ูุชุฎุตุตุฉ ููุฑุงูุฒ ููุงุจุชูุงุฑ. 
ููุง ุดูุฏุช ุงูููุทูุฉ ูููุง ูุจูุฑุง ูู ุนุฏุฏ ุงูุดุฑูุงุช ุงููุงุดุฆุฉ ุงูุชูููุฉุ ูุงูุชู ุชุนูู ุนูู ุชุทููุฑ ุญููู ูุจุชูุฑุฉ ูู ูุฎุชูู ุงููุฌุงูุงุช ูุซู ุงูุชุฌุงุฑุฉ ุงูุฅููุชุฑูููุฉ ูุงูุตุญุฉ ุงูุฑูููุฉ ูุงูุชุนููู ุงูุฅููุชุฑููู.
ูุฐุง ุงูุชุทูุฑ ุงูุณุฑูุน ูุนูุณ ุงูุชุฒุงู ุงูููุทูุฉ ุจููุงูุจุฉ ุงูุชูุฏู ุงูุชูููููุฌู ุงูุนุงููู ูุงูุงุณุชูุงุฏุฉ ูู ุงููุฑุต ุงููุงุฆูุฉ ุงูุชู ุชููุฑูุง ุงูุชูููุงุช ุงูุญุฏูุซุฉ ูุชุญุณูู ุฌูุฏุฉ ุงูุญูุงุฉ ูุชุนุฒูุฒ ุงูููู ุงูุงูุชุตุงุฏู.
            """,
            "Education Article": """
ูุดูุฏ ูุทุงุน ุงูุชุนููู ูู ุงูููุทูุฉ ุงูุนุฑุจูุฉ ุชุญููุง ุฌุฐุฑูุง ูุญู ุงูุชุนููู ุงูุฑููู ูุงูุชุนูู ุนู ุจูุนุฏุ ุฎุงุตุฉ ุจุนุฏ ุฌุงุฆุญุฉ ููููุฏ-19 ุงูุชู ุฃุฌุจุฑุช ุงููุคุณุณุงุช ุงูุชุนููููุฉ ุนูู ุชุจูู ุงูุชูููุงุช ุงูุญุฏูุซุฉ.
ููุฏ ุงุณุชุซูุฑุช ุงูุญูููุงุช ุงูุนุฑุจูุฉ ูููุงุฑุงุช ุงูุฏููุงุฑุงุช ูู ุชุทููุฑ ุงูุจููุฉ ุงูุชุญุชูุฉ ุงูุฑูููุฉ ููุชุนูููุ ุจูุง ูู ุฐูู ุชูููุฑ ุงูุฃุฌูุฒุฉ ุงูููุญูุฉ ููุทูุงุจ ูุชุฏุฑูุจ ุงููุนูููู ุนูู ุงุณุชุฎุฏุงู ุงูุชูููุงุช ุงูุญุฏูุซุฉ.
ููุง ุจุฑุฒุช ููุตุงุช ุงูุชุนูู ุงูุฅููุชุฑููู ุงูุนุฑุจูุฉ ูุจุฏูู ูุนุงู ููุชุนููู ุงูุชูููุฏูุ ุญูุซ ุชูุฏู ูุญุชูู ุชุนููููุง ุนุงูู ุงูุฌูุฏุฉ ุจุงููุบุฉ ุงูุนุฑุจูุฉ ูุบุทู ูุฎุชูู ุงููุฑุงุญู ุงูุฏุฑุงุณูุฉ ูุงูุชุฎุตุตุงุช.
ูุฐุง ุงูุชุญูู ุงูุฑููู ูู ุงูุชุนููู ููุชุญ ุขูุงูุง ุฌุฏูุฏุฉ ุฃูุงู ุงูุทูุงุจ ุงูุนุฑุจ ูููุตูู ุฅูู ุชุนููู ุนุงูู ุงูุฌูุฏุฉ ุจุบุถ ุงููุธุฑ ุนู ูููุนูู ุงูุฌุบุฑุงูู ุฃู ุธุฑูููู ุงูุงูุชุตุงุฏูุฉ.
            """,
            "Health News": """
ุชูุงุฌู ุงูุฃูุธูุฉ ุงูุตุญูุฉ ูู ุงูุนุงูู ุงูุนุฑุจู ุชุญุฏูุงุช ูุจูุฑุฉ ุชุชุทูุจ ุญูููุง ูุจุชูุฑุฉ ูุดุงููุฉ ูุชุญุณูู ุฌูุฏุฉ ุงูุฎุฏูุงุช ุงูุทุจูุฉ ุงูููุฏูุฉ ููููุงุทููู.
ูุชุชุถูู ูุฐู ุงูุชุญุฏูุงุช ููุต ูู ุงูููุงุฏุฑ ุงูุทุจูุฉ ุงููุชุฎุตุตุฉุ ูุนุฏู ุชูุงุฒู ูู ุชูุฒูุน ุงูุฎุฏูุงุช ุงูุตุญูุฉ ุจูู ุงูููุงุทู ุงูุญุถุฑูุฉ ูุงูุฑูููุฉุ ุจุงูุฅุถุงูุฉ ุฅูู ูุญุฏูุฏูุฉ ุงูููุงุฑุฏ ุงููุงููุฉ ุงููุฎุตุตุฉ ูููุทุงุน ุงูุตุญู.
ูููุงุฌูุฉ ูุฐู ุงูุชุญุฏูุงุชุ ุชุชุฌู ุงูุนุฏูุฏ ูู ุงูุฏูู ุงูุนุฑุจูุฉ ูุญู ุชุจูู ุชูููุงุช ุงูุตุญุฉ ุงูุฑูููุฉ ูุซู ุงูุชุทุจูุจ ุนู ุจูุนุฏ ูุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู ุงูุชุดุฎูุต ุงูุทุจูุ ูุงูุชู ุชุณุงุนุฏ ุนูู ุชุญุณูู ุงููุตูู ุฅูู ุงูุฎุฏูุงุช ุงูุตุญูุฉ ูุชูููู ุงูุชูุงููู.
ููุง ุชุนูู ูุฐู ุงูุฏูู ุนูู ุชุทููุฑ ุจุฑุงูุฌ ุงูุชุฃููู ุงูุตุญู ุงูุดุงูู ูุชุญุณูู ุงูุจููุฉ ุงูุชุญุชูุฉ ูููุณุชุดููุงุช ูุงููุฑุงูุฒ ุงูุตุญูุฉ ูุถูุงู ุชูุฏูู ุฑุนุงูุฉ ุตุญูุฉ ุนุงููุฉ ุงูุฌูุฏุฉ ูุฌููุน ุงูููุงุทููู.
            """
        }
        
        selected_sample = st.selectbox("Choose a sample text:", list(sample_texts.keys()))
        if selected_sample:
            input_text = sample_texts[selected_sample]
            st.text_area("Selected text:", value=input_text, height=150, disabled=True)
    
    # Summarization parameters
    with st.expander("โ๏ธ Summarization Settings"):
        col1, col2 = st.columns(2)
        with col1:
            max_length = st.slider("Maximum summary length:", 50, 200, 128)
            min_length = st.slider("Minimum summary length:", 10, 100, 30)
        with col2:
            num_beams = st.slider("Number of beams (for AraBART):", 1, 8, 4)
            show_confidence = st.checkbox("Show confidence scores", True)
    
    # Generate summaries
    if st.button("๐ Generate Summaries", type="primary", key="generate_summaries_btn") and input_text.strip():
        if len(input_text.strip()) < 50:
            st.warning("Please enter a longer text (at least 50 characters) for better summarization.")
            return
        
        results = {}
        timing_data = []
        
        # Progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        total_models = len(selected_models)
        
        for i, model_name in enumerate(selected_models):
            status_text.text(f"Generating summary with {model_name}...")
            
            start_time = time.time()
            
            try:
                if model_name == "Seq2Seq LSTM" and seq2seq_available:
                    if show_confidence:
                        # For Seq2Seq, we don't have confidence, so just generate summary
                        summary = seq2seq.generate_summary(input_text, max_length=max_length)
                        confidence = 0.0  # Placeholder
                    else:
                        summary = seq2seq.generate_summary(input_text, max_length=max_length)
                        confidence = 0.0
                
                elif model_name == "AraBART" and arabart_available:
                    if show_confidence:
                        summary, confidence = arabart.generate_summary_with_confidence(
                            input_text, max_length=max_length, min_length=min_length, num_beams=num_beams
                        )
                    else:
                        summary = arabart.generate_summary(
                            input_text, max_length=max_length, min_length=min_length, num_beams=num_beams
                        )
                        confidence = 0.0
                
                else:
                    continue
                
                inference_time = time.time() - start_time
                
                results[model_name] = {
                    'summary': summary,
                    'confidence': confidence,
                    'time': inference_time,
                    'length': len(summary.split()) if summary else 0
                }
                
                timing_data.append({
                    'Model': model_name,
                    'Time (s)': inference_time
                })
            
            except Exception as e:
                results[model_name] = {
                    'summary': f"Error: {str(e)}",
                    'confidence': 0.0,
                    'time': 0.0,
                    'length': 0
                }
            
            progress_bar.progress((i + 1) / total_models)
        
        progress_bar.empty()
        status_text.empty()
        
        # Display results
        st.subheader("๐ Summarization Results:")
        
        for model_name, result in results.items():
            with st.expander(f"๐ {model_name} Summary", expanded=True):
                st.markdown(f"**Summary ({result['length']} words):**")
                st.markdown(f"<div class='arabic-text'>{result['summary']}</div>", unsafe_allow_html=True)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Inference Time", f"{result['time']:.2f}s")
                with col2:
                    st.metric("Word Count", result['length'])
                with col3:
                    if show_confidence and result['confidence'] > 0:
                        st.metric("Confidence", f"{result['confidence']:.2f}")
                    else:
                        st.metric("Confidence", "N/A")
        
        # Performance comparison
        if len(results) > 1:
            st.subheader("โก Performance Comparison:")
            
            # Timing chart
            if timing_data:
                fig_timing = px.bar(
                    timing_data,
                    x='Model',
                    y='Time (s)',
                    title="Inference Time Comparison",
                    color='Time (s)',
                    color_continuous_scale="RdYlBu_r"
                )
                st.plotly_chart(fig_timing, use_container_width=True)
            
            # Summary comparison table
            comparison_data = []
            for model_name, result in results.items():
                comparison_data.append({
                    'Model': model_name,
                    'Word Count': result['length'],
                    'Time (s)': f"{result['time']:.2f}",
                    'Confidence': f"{result['confidence']:.2f}" if result['confidence'] > 0 else "N/A"
                })
            
            if comparison_data:
                df_comparison = pd.DataFrame(comparison_data)
                st.dataframe(df_comparison, use_container_width=True)
    
    elif st.button("๐ Generate Summaries", type="primary", key="generate_summaries_empty_btn"):
        st.warning("Please enter some text to summarize.")

def main():
    render_summarization_tab()

if __name__ == "__main__":
    main() 